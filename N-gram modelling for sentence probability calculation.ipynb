{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWkzB0-cT7Fw"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from gensim.models import Phrases"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"Thank you so much for your help.\",\n",
        "    \"I really appreciate your help.\",\n",
        "    \"Excuse me, do you know what time it is?\",\n",
        "    \"I’m really sorry for not inviting you.\",\n",
        "    \"I really like your watch.\"\n",
        "]"
      ],
      "metadata": {
        "id": "1akg-hvrUSqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and tokenize the text\n",
        "def preprocess_tokenize(corpus):\n",
        "    tokenized_corpus = [nltk.word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "    return tokenized_corpus"
      ],
      "metadata": {
        "id": "_TSEuLANUT56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate and display unique token frequency table\n",
        "def generate_token_frequency_table(tokenized_corpus):\n",
        "    flattened_corpus = [word for sentence in tokenized_corpus for word in sentence]\n",
        "    token_frequency = Counter(flattened_corpus)\n",
        "    print(\"Token Frequency Table:\")\n",
        "    print(token_frequency)"
      ],
      "metadata": {
        "id": "JBg6uVC3UYuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate bigrams and compute their frequency\n",
        "def generate_bigrams(tokenized_corpus):\n",
        "    bigrams = list(ngrams([word for sentence in tokenized_corpus for word in sentence], 2))\n",
        "    bigram_frequency = Counter(bigrams)\n",
        "    return bigram_frequency"
      ],
      "metadata": {
        "id": "V_jpxyOzUcDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate probability of a sentence using user-defined functions\n",
        "def calculate_sentence_probability(sentence, bigram_frequency):\n",
        "    tokenized_sentence = nltk.word_tokenize(sentence.lower())\n",
        "    probability = 1\n",
        "    for i in range(len(tokenized_sentence) - 1):\n",
        "        bigram = (tokenized_sentence[i], tokenized_sentence[i+1])\n",
        "        probability *= (bigram_frequency[bigram] + 1) / (sum(bigram_frequency.values()) + len(bigram_frequency))\n",
        "    return probability"
      ],
      "metadata": {
        "id": "xNZpxB6DUf2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate probability of a sentence using Gensim package\n",
        "def calculate_sentence_probability_gensim(sentence, bigram_model):\n",
        "    tokenized_sentence = nltk.word_tokenize(sentence.lower())\n",
        "    bigrams = list(bigram_model[tokenized_sentence])\n",
        "    print(bigrams)  # Print bigrams for debugging\n",
        "    if bigrams and all(isinstance(bigram, tuple) and len(bigram) == 2 for bigram in bigrams):\n",
        "        probability = sum(score for _, score in bigrams)\n",
        "    else:\n",
        "        probability = 0\n",
        "    return probability\n"
      ],
      "metadata": {
        "id": "IDwHHfynUhF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# Step 1: Preprocessing and tokenization\n",
        "tokenized_corpus = preprocess_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjC-UYRRUkky",
        "outputId": "19de3eef-252e-4b1b-d00d-be280821f1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Generate and display unique token frequency table\n",
        "generate_token_frequency_table(tokenized_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wzIHgY7UxPa",
        "outputId": "5eda44e2-2dc1-4f28-b078-aad15af62132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Frequency Table:\n",
            "Counter({'.': 4, 'you': 3, 'your': 3, 'i': 3, 'really': 3, 'for': 2, 'help': 2, 'thank': 1, 'so': 1, 'much': 1, 'appreciate': 1, 'excuse': 1, 'me': 1, ',': 1, 'do': 1, 'know': 1, 'what': 1, 'time': 1, 'it': 1, 'is': 1, '?': 1, '’': 1, 'm': 1, 'sorry': 1, 'not': 1, 'inviting': 1, 'like': 1, 'watch': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Generate bigrams and compute their frequency\n",
        "bigram_frequency = generate_bigrams(tokenized_corpus)"
      ],
      "metadata": {
        "id": "7raj-nHXVF6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Take sample sentence as an input to the system and compute its probability\n",
        "test_sentences = [\n",
        "    \"I really like your garden\",\n",
        "    \"I really sorry for your garden\",\n",
        "    \"I really appropriate your garden\",\n",
        "    \"I really appreciate your garden\"\n",
        "]"
      ],
      "metadata": {
        "id": "0QHp3dfHVXrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate probability using user-defined functions\n",
        "print(\"\\nProbability of sentences using user-defined functions:\")\n",
        "for sentence in test_sentences:\n",
        "    probability = calculate_sentence_probability(sentence, bigram_frequency)\n",
        "    print(f\"Sentence: '{sentence}', Probability: {probability}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEDDvX2lVbT6",
        "outputId": "a9109274-25e0-425f-87bc-17227883d962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probability of sentences using user-defined functions:\n",
            "Sentence: 'I really like your garden', Probability: 3.5968876850239016e-07\n",
            "Sentence: 'I really sorry for your garden', Probability: 9.465493907957636e-09\n",
            "Sentence: 'I really appropriate your garden', Probability: 8.992219212559754e-08\n",
            "Sentence: 'I really appreciate your garden', Probability: 3.5968876850239016e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate probability using Gensim package\n",
        "print(\"\\nProbability of sentences using Gensim package:\")\n",
        "bigram_model = Phrases(tokenized_corpus)\n",
        "for sentence in test_sentences:\n",
        "    probability = calculate_sentence_probability_gensim(sentence, bigram_model)\n",
        "    print(f\"Sentence: '{sentence}', Probability: {probability}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9VN0dL4VdO6",
        "outputId": "eca02a14-3a56-4772-b1c8-d8d6735bb6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probability of sentences using Gensim package:\n",
            "['i', 'really', 'like', 'your', 'garden']\n",
            "Sentence: 'I really like your garden', Probability: 0\n",
            "['i', 'really', 'sorry', 'for', 'your', 'garden']\n",
            "Sentence: 'I really sorry for your garden', Probability: 0\n",
            "['i', 'really', 'appropriate', 'your', 'garden']\n",
            "Sentence: 'I really appropriate your garden', Probability: 0\n",
            "['i', 'really', 'appreciate', 'your', 'garden']\n",
            "Sentence: 'I really appreciate your garden', Probability: 0\n"
          ]
        }
      ]
    }
  ]
}