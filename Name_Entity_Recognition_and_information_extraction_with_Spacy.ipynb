{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX9UmsoTCcrH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "hyLsd0rvGMuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv('/content/News.csv')\n",
        "\n",
        "# Select the first 10 rows\n",
        "data_subset = data.head(10)\n",
        "\n",
        "# Iterate over each row in the subset and process the text\n",
        "for index, row in data_subset.iterrows():\n",
        "    # Process the text using spaCy\n",
        "    doc = nlp(row['News'])\n",
        "\n",
        "    # Print entities and their labels\n",
        "    for ent in doc.ents:\n",
        "        print(ent.text, ent.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2-2IMmpGirG",
        "outputId": "4eef5b98-30e5-4211-a44a-73dae262da7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "third ORDINAL\n",
            "George W. PERSON\n",
            "Hillary Clinton PERSON\n",
            "John McCain PERSON\n",
            "George Bush PERSON\n",
            "Iran GPE\n",
            "the last 10 years DATE\n",
            "the last two decades DATE\n",
            "Jim Dunnam PERSON\n",
            "years DATE\n",
            "just last year DATE\n",
            "Russ Feingold PERSON\n",
            "Watergate EVENT\n",
            "$19.5 million MONEY\n",
            "Oregon Lottery FAC\n",
            "the Port of Newport FAC\n",
            "NOAA Marine Operations Center-Pacific ORG\n",
            "GOP ORG\n",
            "Glenn Grothman PERSON\n",
            "Joe Leibham PERSON\n",
            "$788 million MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "WJYpfgo0Gm1G",
        "outputId": "a751f72c-b6da-4214-d5b3-08b165f63a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Says \\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    GOP\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n primary opponents \\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Glenn Grothman\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\\n</mark>\\n and \\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Joe Leibham\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\\n</mark>\\n cast a compromise vote that cost \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $788 million\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n in higher electricity costs.</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emnVAULCH4FG",
        "outputId": "33ceca50-0c76-4648-b491-058d76f095ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize each entry in the 'text' column\n",
        "sent = data['News'].apply(nltk.word_tokenize)\n",
        "\n",
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uflIaU7JIJLO",
        "outputId": "0ef393e7-7d0c-4ad6-803e-282e6c149482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [Says, the, Annies, List, political, group, su...\n",
              "1        [When, did, the, decline, of, coal, start, ?, ...\n",
              "2        [Hillary, Clinton, agrees, with, John, McCain,...\n",
              "3        [Health, care, reform, legislation, is, likely...\n",
              "4        [The, economic, turnaround, started, at, the, ...\n",
              "                               ...                        \n",
              "10235    [There, are, a, larger, number, of, shark, att...\n",
              "10236    [Democrats, have, now, become, the, party, of,...\n",
              "10237    [Says, an, alternative, to, Social, Security, ...\n",
              "10238    [On, lifting, the, U.S., Cuban, embargo, and, ...\n",
              "10239    [The, Department, of, Veterans, Affairs, has, ...\n",
              "Name: News, Length: 10240, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "#sent1=nltk.pos_tag(sent)\n",
        "sent1 = sent.apply(nltk.pos_tag)\n",
        "sent1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Xl4MG0IQeV",
        "outputId": "5516f167-6330-4604-f8ab-bb02541f4a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [(Says, VBZ), (the, DT), (Annies, NNPS), (List...\n",
              "1        [(When, WRB), (did, VBD), (the, DT), (decline,...\n",
              "2        [(Hillary, NNP), (Clinton, NNP), (agrees, VBZ)...\n",
              "3        [(Health, NNP), (care, NN), (reform, NN), (leg...\n",
              "4        [(The, DT), (economic, JJ), (turnaround, NN), ...\n",
              "                               ...                        \n",
              "10235    [(There, EX), (are, VBP), (a, DT), (larger, JJ...\n",
              "10236    [(Democrats, NNPS), (have, VBP), (now, RB), (b...\n",
              "10237    [(Says, VBZ), (an, DT), (alternative, NN), (to...\n",
              "10238    [(On, IN), (lifting, VBG), (the, DT), (U.S., N...\n",
              "10239    [(The, DT), (Department, NNP), (of, IN), (Vete...\n",
              "Name: News, Length: 10240, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "cp = nltk.RegexpParser(pattern)\n",
        "#cs = cp.parse(sent1)\n",
        "cs = sent1.apply(cp.parse)\n",
        "print(cs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4kgiZUoI6cF",
        "outputId": "3081947a-a6a8-4304-e885-ef5962f7772e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [(Says, VBZ), (the, DT), (Annies, NNPS), (List...\n",
            "1        [(When, WRB), (did, VBD), [(the, DT), (decline...\n",
            "2        [(Hillary, NNP), (Clinton, NNP), (agrees, VBZ)...\n",
            "3        [(Health, NNP), [(care, NN)], [(reform, NN)], ...\n",
            "4        [[(The, DT), (economic, JJ), (turnaround, NN)]...\n",
            "                               ...                        \n",
            "10235    [(There, EX), (are, VBP), (a, DT), (larger, JJ...\n",
            "10236    [(Democrats, NNPS), (have, VBP), (now, RB), (b...\n",
            "10237    [(Says, VBZ), [(an, DT), (alternative, NN)], (...\n",
            "10238    [(On, IN), (lifting, VBG), (the, DT), (U.S., N...\n",
            "10239    [(The, DT), (Department, NNP), (of, IN), (Vete...\n",
            "Name: News, Length: 10240, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "ne_tree = nltk.ne_chunk(pos_tag(word_tokenize(row['News'])))\n",
        "print(ne_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7aqefqdK4Vn",
        "outputId": "367e49db-4962-4789-ee36-02722b36c072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  Says/VBZ\n",
            "  (ORGANIZATION GOP/NNP)\n",
            "  primary/JJ\n",
            "  opponents/NNS\n",
            "  (PERSON Glenn/NNP Grothman/NNP)\n",
            "  and/CC\n",
            "  (PERSON Joe/NNP Leibham/NNP)\n",
            "  cast/VBD\n",
            "  a/DT\n",
            "  compromise/NN\n",
            "  vote/NN\n",
            "  that/IN\n",
            "  cost/VBD\n",
            "  $/$\n",
            "  788/CD\n",
            "  million/CD\n",
            "  in/IN\n",
            "  higher/JJR\n",
            "  electricity/NN\n",
            "  costs/NNS\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv('/content/News.csv')\n",
        "\n",
        "# Define a function to extract relationships between entities using dependency parsing\n",
        "def extract_relationships(doc):\n",
        "    relationships = []\n",
        "    for token in doc:\n",
        "        if token.dep_ in ('attr', 'dobj'):\n",
        "            subject = [w for w in token.head.lefts if w.dep_ == 'nsubj']\n",
        "            if subject:\n",
        "                subject = subject[0]\n",
        "                relationships.append((subject, token))\n",
        "    return relationships\n",
        "\n",
        "# Iterate over each row in the dataset and process the text\n",
        "tuples_extracted = []\n",
        "for index, row in data.iterrows():\n",
        "    # Process the text using spaCy\n",
        "    doc = nlp(row['News'])\n",
        "\n",
        "    # Extract entities and their labels\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "    # Extract relationships between entities using dependency parsing\n",
        "    relationships = extract_relationships(doc)\n",
        "\n",
        "    # Construct tuples for information extraction\n",
        "    for subj, obj in relationships:\n",
        "        tuples_extracted.append((subj.text, obj.text, obj.dep_))\n",
        "\n",
        "# Display the number of tuples extracted\n",
        "print(\"Number of tuples extracted:\", len(tuples_extracted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-4zEzwlcYrO",
        "outputId": "a004605b-47c3-4990-8624-79d682438ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tuples extracted: 8462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a9SjoeDbPOfS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}